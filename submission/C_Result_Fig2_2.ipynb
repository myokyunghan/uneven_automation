{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result_Fig2_2 : Difficulty with Tag Availability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "p = os.path.abspath('..')\n",
    "sys.path.insert(1, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lib.stats.stats as st\n",
    "from utils.statistics import *\n",
    "from lib.distribution_collector import (collect_tag_distributions)\n",
    "from constants import CONSTANTS\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from utils.statistics import *\n",
    "import config.config as conf\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = CONSTANTS.s_tag_result_path\n",
    "file_list = os.listdir(f'{path}/raw')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "for i in file_list:\n",
    "\twith open(f'{path}/raw/{i}', 'rb') as f:\n",
    "\t\tdf = pd.concat([df, pickle.load(f)], axis = 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1257012, 6)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_date = datetime.datetime(2022, 11, 30)\n",
    "pre_std_date = datetime.datetime(2021, 12, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cdate'] = pd.to_datetime(df['cdate'], format=\"%Y-%m-%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rel_week'] = np.floor((df['cdate']-std_date).dt.days/7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bf_pro = df[df['rel_week']<0].groupby(['tag']).sum(['pct'])['pct'].sort_values().reset_index()\n",
    "tagnum = int(np.floor(df_bf_pro.shape[0]*0.2))\n",
    "bot_tag = list(df_bf_pro.iloc[:tagnum, 0])\n",
    "top_tag = list(df_bf_pro.iloc[tagnum:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot = df.groupby(['rel_week']).sum(['pct'])['pct'].reset_index(name = 'tot_pct')\n",
    "df_pct = pd.merge(df, df_tot, on = 'rel_week')\n",
    "\n",
    "df_pct['pct_pct'] = df_pct['pct']/df_pct['tot_pct']\n",
    "\n",
    "df_pct_bot = df_pct[df_pct['tag'].isin(bot_tag)]\n",
    "df_pct_top = df_pct[df_pct['tag'].isin(top_tag)]\n",
    "\n",
    "df_pct_top_tot = df_pct_top.groupby(['rel_week']).sum(['pct_pct'])['pct_pct'].reset_index()\n",
    "df_pct_bot_tot = df_pct_bot.groupby(['rel_week']).sum(['pct_pct'])['pct_pct'].reset_index()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "proportion_dict = {'Top 20% Tags' : df_pct_top_tot\n",
    "                ,   'Bottom 20% Tags' : df_pct_bot_tot}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{path}/agg/weekly_tag_distributions.pkl', 'rb') as f:\n",
    "    weekly_tag_distributions = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ginis = list(map(lambda x: calculate_gini(list(x.values())), weekly_tag_distributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entropies = list(map(lambda x: calculate_entropy(list(x.values())), weekly_tag_distributions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_entropy_dict = {'Gini Coefficient' : ginis, 'Entropy' : entropies}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_week = np.array(np.arange(-52, 52))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_0 = st.Stats(rel_week, entropies, 2, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_stat_0, p_value_0 = st_0.chow_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sharey = False \n",
    "sharex = True \n",
    "g_num  = len(proportion_dict.items())\n",
    "\n",
    "fig, axs = plt.subplots(1, 3, figsize = (18, 6), constrained_layout=True)\n",
    "alpha_list = [0.6, 0.5]\n",
    "color_list = [\"#a6d96a\", \"#1a9850\"]\n",
    "\n",
    "for x, (title, proportion) in enumerate(proportion_dict.items()):\n",
    "    rel_week = list(proportion['rel_week'])\n",
    "    values = list(proportion['pct_pct'])\n",
    "    \n",
    "    axs[x].bar(rel_week, values, color=color_list[x], width=1.0, align='center', alpha=alpha_list[x]\n",
    "    )\n",
    "    axs[x].axvline(x=0, color='tab:red', linestyle='-.', linewidth=1)\n",
    "\n",
    "    if x ==0 :\n",
    "        axs[x].set_ylim(0.85, 1.0)\n",
    "        axs[x].set_yticks(np.arange(0.85, 1.01, 0.05))\n",
    "\n",
    "    # axs[x].set_title(f'{title}', fontsize=25)\n",
    "\n",
    "    axs[x].text(0.5, 1.05, f\"{title}\",\n",
    "            ha='center', va='bottom', fontsize=22, fontweight='bold', transform=axs[x].transAxes)\n",
    "\n",
    "    axs[x].text(0.5, 1.00, \"\",\n",
    "        ha='center', va='bottom', fontsize=15, transform=axs[x].transAxes)  \n",
    "    axs[x].tick_params(axis='x', labelsize=16)\n",
    "    axs[x].tick_params(axis='y', labelsize=16)\n",
    "\n",
    "idx = 2\n",
    "list_ = gini_entropy_dict['Entropy']\n",
    "x_rel, divider = get_dist_x_div(list_)\n",
    "\n",
    "reg_bf = calc_regression_with_ci(x_rel[:divider], list_[:divider])\n",
    "reg_af = calc_regression_with_ci(x_rel[divider:], list_[divider:])\n",
    "\n",
    "reg_bf_summary = reg_bf[\"pred_summary\"]\n",
    "reg_af_summary = reg_af[\"pred_summary\"]\n",
    "\n",
    "# 회귀선 (예측값)\n",
    "reg_bf_y_pred = reg_bf_summary[\"mean\"]\n",
    "reg_af_y_pred = reg_af_summary[\"mean\"]\n",
    "# 신뢰구간\n",
    "reg_bf_ci_lower = reg_bf_summary[\"mean_ci_lower\"]\n",
    "reg_bf_ci_upper = reg_bf_summary[\"mean_ci_upper\"]\n",
    "\n",
    "reg_af_ci_lower = reg_af_summary[\"mean_ci_lower\"]\n",
    "reg_af_ci_upper = reg_af_summary[\"mean_ci_upper\"]\n",
    "\n",
    "p_value_txt = '($p < 0.001$)' if p_value_0 <0.001 else '($p = {p_value_0:.3f}$)'\n",
    "\n",
    "axs[idx].scatter(x_rel, list_, color = 'darkgray', alpha = 0.7,  s=10, marker='x')\n",
    "axs[idx].axvline(x=0, color='tab:red', linestyle='-.', linewidth=1)\n",
    "# axs[idx].set_ylabel(f\"{measure} of Topic Distribution\", fontsize = 10)\n",
    "axs[idx].plot(x_rel[:divider], reg_bf_y_pred, linewidth=2, label = 'before ChatGPT')\n",
    "axs[idx].plot(x_rel[divider:], reg_af_y_pred, linewidth=2, label = 'after ChatGPT')\n",
    "\n",
    "axs[idx].fill_between(x_rel[:divider], reg_bf_ci_lower, reg_bf_ci_upper, alpha=0.1)\n",
    "axs[idx].fill_between(x_rel[divider:], reg_af_ci_lower, reg_af_ci_upper, alpha=0.1)\n",
    "\n",
    "axs[idx].legend(frameon=False, loc='best', fontsize=14)\n",
    "# axs[idx].set_title(f\"Changes in Entropy (tag)\", fontsize=25)\n",
    "axs[idx].text(0.5, 1.05, f\"Changes in Entropy (tag)\",\n",
    "            ha='center', va='bottom', fontsize=22, fontweight='bold', transform=axs[idx].transAxes)\n",
    "\n",
    "axs[idx].text(0.5, 1.00, f\"{p_value_txt}\",\n",
    "        ha='center', va='bottom', fontsize=15, transform=axs[idx].transAxes)  \n",
    "\n",
    "axs[idx].tick_params(axis='x', labelsize=16)\n",
    "axs[idx].tick_params(axis='y', labelsize=16)\n",
    "\n",
    "\n",
    "axs[0].set_ylabel(\"Accumulated tag share\", fontsize = 22)\n",
    "axs[2].set_ylabel(f\"Entropy\", fontsize = 22)\n",
    "\n",
    "fig.supxlabel(\"Weeks relative to ChatGPT release\", fontsize=22) \n",
    "plt.savefig(f\"{output_dir}C_Result_Fig2_2.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_uneven_automation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
